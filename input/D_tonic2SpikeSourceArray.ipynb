{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "download = not os.path.isfile('data/nmnist_test.zip')\n",
    "download\n",
    "\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "\n",
    "testset = tonic.datasets.NMNIST(save_to='./data', download=download, train=False)\n",
    "testloader = tonic.datasets.DataLoader(testset,\n",
    "                                       batch_size=1,\n",
    "                                       shuffle=True)\n",
    "\n",
    "events, target = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tonic.utils import plot_events\n",
    "plot_events(events.squeeze(), sensor_size=testset.sensor_size, ordering=testset.ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.5\n",
      "IPython version      : 7.18.1\n",
      "\n",
      "numpy     : 1.19.2\n",
      "matplotlib: 3.3.2\n",
      "pyNN      : 0.9.5\n",
      "neo       : 0.8.0\n",
      "moviepy   : 1.0.3\n",
      "imageio   : 2.9.0\n",
      "\n",
      "Compiler    : GCC 9.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-53-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: inv-ope-de06\n",
      "\n",
      "Git hash: 4b4c65e8f06f3149c6e7814c12e967d55b9e0e2e\n",
      "\n",
      "Git repo: https://github.com/SpikeAI/2020-11_brainhack_Project7\n",
      "\n",
      "Git branch: main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run boilerplate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 34), 'xytp')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.sensor_size, testset.ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_pop = np.prod(testset.sensor_size)\n",
    "N_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2901, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timings are in microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0044, 0.0052, 0.0058,  ..., 0.3027, 0.3053, 0.3059])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[0, :, testset.ordering.find(\"t\")]*1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_x = testset.ordering.find(\"x\")\n",
    "index_y = testset.ordering.find(\"y\")\n",
    "index_t = testset.ordering.find(\"t\")\n",
    "index_x, index_y, index_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([19, 18, 19,  ..., 22,  8, 33], dtype=torch.int32),\n",
       " tensor([16, 30, 20,  ..., 11, 11, 25], dtype=torch.int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[0, :, index_x], events[0, :, index_y] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[0, :, index_x] == events[0, 0, index_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[0, :, index_y] == events[0, :, index_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(events[0, :, index_x] == events[0, :, index_x]) & (events[0, :, index_y] == events[0, :, index_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2898, 2899, 2900])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((events[0, :, index_x] == events[0, :, index_x]) & (events[0, :, index_y] == events[0, :, index_y]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4430,   5237,   5779,  ..., 302699, 305312, 305912],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[0, np.where((events[0, :, index_x] == events[0, :, index_x]) & (events[0, :, index_y] == events[0, :, index_y]))[0], index_t ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1156,\n",
       " [4.43,\n",
       "  46.005,\n",
       "  49.987,\n",
       "  67.01,\n",
       "  73.122,\n",
       "  152.729,\n",
       "  248.547,\n",
       "  253.359,\n",
       "  256.815,\n",
       "  260.26800000000003,\n",
       "  281.295,\n",
       "  295.78700000000003],\n",
       " 2901)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_np = events.numpy()\n",
    "cellSourceSpikes = []\n",
    "for i in range(N_pop):\n",
    "    row = i//(testset.sensor_size[0])\n",
    "    col = i%(testset.sensor_size[0])\n",
    "    spike_idx = np.where((events_np[0, :, index_x] == row) & (events_np[0, :, index_y] == col))[0]\n",
    "    spike_times = events_np[0, spike_idx, index_t] * 1.e-3 # in milliseconds\n",
    "    cellSourceSpikes.append(spike_times)\n",
    "\n",
    "cellSourceSpikes = [list(elem) for elem in cellSourceSpikes]\n",
    "idx = events[0, 0, index_x]*(testset.sensor_size[0]) + events[0, 0, index_y] # first spike\n",
    "len(cellSourceSpikes), cellSourceSpikes[idx], np.sum([len(st) for st in cellSourceSpikes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSAConnector: libneurosim support not available in NEST.\n",
      "Falling back on PyNN's default CSAConnector.\n",
      "Please re-compile NEST using --with-libneurosim=PATH\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pyNN.spiNNaker as sim\n",
    "    simulator = 'spinnaker'\n",
    "except ModuleNotFoundError:\n",
    "    import pyNN.nest as sim\n",
    "    simulator = 'nest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.setup(timestep=dt,\n",
    "          min_delay=1,\n",
    "          max_delay=100,\n",
    "          debug=0)\n",
    "\n",
    "sources = sim.SpikeSourceArray(spike_times=cellSourceSpikes)\n",
    "spikeSource = sim.Population(N_pop, sources)    \n",
    "spikeSource.record(['spikes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.run(simtime=simtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeSources  = spikeSource.get_data()#.segments[0].spiketrains\n",
    "S_spikes = spikeSources.segments[0].spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.43 ,  46.005,  49.987,  67.01 ,  73.122, 152.729, 248.547,\n",
       "       253.359, 256.815, 260.268, 281.295, 295.787])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = S_spikes[idx]\n",
    "st.as_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spikelist2numpy(spikelist):\n",
    "    output_spike = np.zeros((testset.sensor_size[0], testset.sensor_size[1], time_bins))\n",
    "    for i, spiketrain in enumerate(spikelist):\n",
    "        row = i//(testset.sensor_size[0])\n",
    "        col = i%(testset.sensor_size[0])\n",
    "        for spiketime in spiketrain.as_array():\n",
    "            # print(int(spiketime))\n",
    "            output_spike[row, col, int(spiketime)] = 1\n",
    "    return output_spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie.min()=0.0 - movie.max()=1.0 \n"
     ]
    }
   ],
   "source": [
    "nmnist_spike = spikelist2numpy(S_spikes)\n",
    "minmax(nmnist_spike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  22%|██▏       | 77/350 [00:00<00:00, 763.10it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output/nmnist_spike.mp4.\n",
      "Moviepy - Writing video output/nmnist_spike.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output/nmnist_spike.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"output/nmnist_spike.mp4\" loop autoplay width=\"100%\" ></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(make_movie(nmnist_spike, label='nmnist_spike'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 34, 350)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmnist_spike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2897.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmnist_spike.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.prophesee.ai/resources/Prophesee_Dataset_n_cars.zip to ./data/Prophesee_Dataset_n_cars.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75dc5467c3a4eeb9c7ccc31bda5f84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download = not os.path.isfile('data/Prophesee_Dataset_n_cars.zip')\n",
    "\n",
    "testset = tonic.datasets.NCARS(save_to='./data', download=download, train=False)\n",
    "testloader = tonic.datasets.DataLoader(testset,\n",
    "                                       batch_size=1,\n",
    "                                       shuffle=True)\n",
    "\n",
    "events, target = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_np = events.numpy()\n",
    "cellSourceSpikes = []\n",
    "simtime = 0\n",
    "for i in range(N_pop):\n",
    "    row = i//(testset.sensor_size[0])\n",
    "    col = i%(testset.sensor_size[0])\n",
    "    spike_idx = np.where((events_np[0, :, index_x] == row) & (events_np[0, :, index_y] == col))[0]\n",
    "    spike_times = events_np[0, spike_idx, index_t] * 1.e-3 # in milliseconds\n",
    "    cellSourceSpikes.append(spike_times)\n",
    "    simtime = np.max(simtime, np.max(spike_times))\n",
    "\n",
    "cellSourceSpikes = [list(elem) for elem in cellSourceSpikes]\n",
    "idx = events[0, 0, index_x]*(testset.sensor_size[0]) + events[0, 0, index_y] # first spike\n",
    "len(cellSourceSpikes), cellSourceSpikes[idx], np.sum([len(st) for st in cellSourceSpikes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.setup(timestep=dt,\n",
    "          min_delay=1,\n",
    "          max_delay=100,\n",
    "          debug=0)\n",
    "\n",
    "sources = sim.SpikeSourceArray(spike_times=cellSourceSpikes)\n",
    "spikeSource = sim.Population(N_pop, sources)    \n",
    "spikeSource.record(['spikes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.run(simtime=simtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeSources  = spikeSource.get_data()#.segments[0].spiketrains\n",
    "S_spikes = spikeSources.segments[0].spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.43 ,  46.005,  49.987,  67.01 ,  73.122, 152.729, 248.547,\n",
       "       253.359, 256.815, 260.268, 281.295, 295.787])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = S_spikes[idx]\n",
    "st.as_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spikelist2numpy(spikelist):\n",
    "    output_spike = np.zeros((testset.sensor_size[0], testset.sensor_size[1], time_bins))\n",
    "    for i, spiketrain in enumerate(spikelist):\n",
    "        row = i//(testset.sensor_size[0])\n",
    "        col = i%(testset.sensor_size[0])\n",
    "        for spiketime in spiketrain.as_array():\n",
    "            # print(int(spiketime))\n",
    "            output_spike[row, col, int(spiketime)] = 1\n",
    "    return output_spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie.min()=0.0 - movie.max()=1.0 \n"
     ]
    }
   ],
   "source": [
    "nmnist_spike = spikelist2numpy(S_spikes)\n",
    "minmax(nmnist_spike)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
